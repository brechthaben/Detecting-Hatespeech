{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTAN6lXZAukk"
      },
      "source": [
        "# Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "HgA3sNs8Aukm"
      },
      "outputs": [],
      "source": [
        "# add code here\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "#setting up\n",
        "spark = SparkSession.builder.appName(\"HateSpeechPrediction\").getOrCreate()\n",
        "\n",
        "#creating features\n",
        "data = spark.createDataFrame(df) #df is cleaned dataframe from pre-processing\n",
        "feature_cols = [col for col in data.columns if col != 'hate_speech_score'] #exclude hatespeech score from features\n",
        "\n",
        "#transforming df\n",
        "va = VectorAssembler(inputCols = feature_cols, outputCol='features')\n",
        "va_df = assembler.transform(data).select('features', 'hate_speech_score')\n",
        "va_df = va_df.withColumnRenamed('hate_speech_score', 'label')\n",
        "va_df.show(3)\n",
        "\n",
        "#creating first model (random forest)\n",
        "model1= RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "model1 = model1.fit(va_df)\n",
        "\n",
        "test_data = spark.createDataFrame(bluesky) #bluesky posts accessed via api\n",
        "test_va_df = assembler.transform(test_data)\n",
        "\n",
        "#predictions for first model - we still need evaluation + model summary\n",
        "predictions_1 = model1.transform(test_va_df)\n",
        "predictions_1.select('features', 'prediction').show(3)\n",
        "\n",
        "#creating second model (gradient boosted trees)\n",
        "model2 = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
        "model2 = model2.fit(va_df)\n",
        "\n",
        "#predictions for second model\n",
        "predictions_2 = model2.transform(test_va_df)\n",
        "predictions_2.select('features', 'prediction').show(3)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}